{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train_9_11.csv')\n",
    "weather = pd.read_csv('data/weather_3_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60578, 24552)"
      ]
     },
     "execution_count": 818,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train),len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 是否工作日，周末\n",
    "train['isweekend'] = train['dayofweek'].apply(lambda x: 1 if x==5 or x==6 else 0)\n",
    "train['isweekday'] = 1 - train['isweekend']\n",
    "train['day'] = train['ymd'].apply(lambda x: int(x[-2:]))\n",
    "train['month'] = train['ymd'].apply(lambda x: int(x[5:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, weather, on=['ymd'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 地点小时均值，带衰减权重\n",
    "def getmean(df):\n",
    "    num = df['num'].values\n",
    "    weights = [ 0.85**i for i in range(len(num),0,-1) ] \n",
    "    return sum(num*weights)/sum(weights)\n",
    "train = pd.merge(train,\\\n",
    "train.loc[(train['ymd']<'2017-11-24')&(train.month.isin([10,11])),:].groupby(['loc_id', 'hour']).apply(getmean).reset_index().rename(columns={0:'loc_hour_mean'}),\\\n",
    "                on=['loc_id', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 地点星期小时均值，带衰减权重\n",
    "train = pd.merge(train,\\\n",
    "train.loc[(train['ymd']<'2017-11-24')&(train.month.isin([10,11])),:].groupby(['loc_id', 'dayofweek', 'hour']).apply(getmean).reset_index().rename(columns={0:'loc_week_hour_mean'}),\\\n",
    "                on=['loc_id', 'dayofweek', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 小时分区\n",
    "hour_bins = [-1, 6,19, 23]\n",
    "train['hour_cut'] = pd.cut(train.hour, hour_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 月份分区，上、中、下旬\n",
    "day_bins = [0, 10, 20, 31]\n",
    "train['day_cut'] = pd.cut(train.day, day_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 地点简单分类，食堂，教学楼，公寓\n",
    "train['loc_type'] = 0\n",
    "train.loc[train['loc_id'].isin([8,10,12,29]),'loc_type'] = 1  # 食堂\n",
    "train.loc[train['loc_id'].isin([16,33,27,15,22,24,14,20]),'loc_type'] = 2 # 教室"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "            'loc_id','loc_type',\n",
    "            'month','day','day_cut',\n",
    "            'hour','hour_cut',\n",
    "            'dayofweek','isweekday', 'isweekend',\n",
    "            'loc_hour_mean','loc_week_hour_mean',\n",
    "            'maxTem','minTem',\n",
    "            'wea','pm','rain'\n",
    "             ]\n",
    "label = ['num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17088, 17)\n",
      "(5416, 17)\n"
     ]
    }
   ],
   "source": [
    "# 仅用11月数据训练模型\n",
    "X_train = train.loc[(train['ymd']<'2017-11-24')&(train.month.isin([11])), features]\n",
    "X_valid = train.loc[(train['ymd']>'2017-11-23'), features]\n",
    "y_train = train.loc[(train['ymd']<'2017-11-24')&(train.month.isin([11])), label].num.values\n",
    "y_valid = train.loc[(train['ymd']>'2017-11-23'), label].num.values\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 20 rounds.\n",
      "[100]\ttraining's rmse: 377.424\tvalid_1's rmse: 335.874\n",
      "[200]\ttraining's rmse: 188.941\tvalid_1's rmse: 173.94\n",
      "[300]\ttraining's rmse: 134.392\tvalid_1's rmse: 157.952\n",
      "Early stopping, best iteration is:\n",
      "[281]\ttraining's rmse: 140.182\tvalid_1's rmse: 157.398\n"
     ]
    }
   ],
   "source": [
    "lgb_params = {\n",
    "        'boosting': 'gbrt',\n",
    "        'max_depth': 10,\n",
    "        'num_leaves': 60,\n",
    "        'learning_rate': 0.01,\n",
    "        'colsample_bytree': 0.5,\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'min_data_in_leaf':10,\n",
    "        'verbose': -1,\n",
    "        'nthread': 12,\n",
    "    }\n",
    "\n",
    "d_train = lgb.Dataset(X_train, label=y_train)\n",
    "d_valid = lgb.Dataset(X_valid, label=y_valid)\n",
    "watchlist = [d_train, d_valid]\n",
    "\n",
    "model = lgb.train(lgb_params, train_set=d_train, num_boost_round=2000, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=20, verbose_eval=100)\n",
    "lgb_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    assert len(y) == len(y_pred)\n",
    "    return (sum((y_pred - y)** 2.0)/len(y)) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf rmse: 162.042359538\n",
      "CPU times: user 3.82 s, sys: 96 ms, total: 3.92 s\n",
      "Wall time: 779 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "rf = RandomForestRegressor(n_estimators=200, max_depth=8, max_features='sqrt', n_jobs=16)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_valid)\n",
    "print('rf rmse:', rmse(y_valid, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm rmse: 166.579781058\n",
      "CPU times: user 7.81 s, sys: 4 ms, total: 7.81 s\n",
      "Wall time: 7.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm = GradientBoostingRegressor(learning_rate=0.01,\n",
    "                                n_estimators=1000,\n",
    "                                max_depth=6,\n",
    "                                max_features='sqrt',\n",
    "                                criterion='mse',\n",
    "                               )\n",
    "gbm.fit(X_train, y_train)\n",
    "gbm_pred = gbm.predict(X_valid)\n",
    "print('gbm rmse:', rmse(y_valid, gbm_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rule_ans = train.loc[(train['ymd']<'2017-11-24')&(train.month.isin([10,11]))].groupby(['loc_id', 'dayofweek', 'hour']).\\\n",
    "    apply(getmean).reset_index().rename(columns={0:'num_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rule_pred = pd.merge(X_valid, rule_ans, on=['loc_id','dayofweek','hour'], how='left').fillna(0)['num_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.04012540634545"
      ]
     },
     "execution_count": 901,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(y_valid, rule_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\tScore: 152.63792965208395\tWeights: 0.308056626579\t0.214292326739\t0.466847895059\t-0.0259527494745\n",
      "2\tScore: 152.63792964875674\tWeights: 0.30803580382\t0.214316163276\t0.466843889368\t-0.0259513303562\n",
      "3\tScore: 152.6379296485751\tWeights: 0.308042023479\t0.214322172691\t0.466837752444\t-0.0259570704885\n",
      "4\tScore: 152.63792964854653\tWeights: 0.308065722588\t0.214311739818\t0.466839792867\t-0.0259720373433\n",
      "5\tScore: 152.63792964884126\tWeights: 0.308058397746\t0.214303473549\t0.466860322223\t-0.0259775902444\n",
      "6\tScore: 152.63792964563828\tWeights: 0.308062261321\t0.214300870092\t0.466846752795\t-0.0259647723524\n",
      "7\tScore: 152.6379296459248\tWeights: 0.308054773416\t0.214302164733\t0.466853937917\t-0.0259660818549\n",
      "8\tScore: 152.6379297114536\tWeights: 0.308093237842\t0.214272745909\t0.466790533181\t-0.0259084699497\n",
      "9\tScore: 152.63792981023124\tWeights: 0.308052947979\t0.214425326235\t0.466740898378\t-0.0259728978956\n",
      "10\tScore: 152.63792964543654\tWeights: 0.308058214038\t0.214300177357\t0.466848467979\t-0.0259617996582\n",
      "CPU times: user 440 ms, sys: 0 ns, total: 440 ms\n",
      "Wall time: 440 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 使用验证集的预测结果来确定模型融合的参数\n",
    "blend_train= []\n",
    "res_list = []\n",
    "weights_list = []\n",
    "blend_train.append(lgb_pred)\n",
    "blend_train.append(rf_pred)\n",
    "blend_train.append(gbm_pred)\n",
    "blend_train.append(rule_pred)\n",
    "blend_train = np.array(blend_train)\n",
    "\n",
    "def rmse_min_func(weights):\n",
    "    final_prediction = 0\n",
    "    for weight, prediction in zip(weights, blend_train):\n",
    "        final_prediction += weight * prediction\n",
    "    return np.sqrt(mean_squared_error(y_valid, final_prediction))\n",
    "\n",
    "for k in range(10):\n",
    "    starting_values = np.random.uniform(size=len(blend_train))\n",
    "    bounds = [(-1, 1)] * len(blend_train)\n",
    "\n",
    "    res = minimize(rmse_min_func,\n",
    "                   starting_values,\n",
    "                   method='L-BFGS-B',\n",
    "                   bounds=bounds,\n",
    "                   options={'disp': False,\n",
    "                            'maxiter': 100000})\n",
    "    res_list.append(res['fun'])\n",
    "    weights_list.append(res['x'])\n",
    "    print('{iter}\\tScore: {score}\\tWeights: {weights}'.format(\n",
    "        iter=(k + 1),\n",
    "        score=res['fun'],\n",
    "        weights='\\t'.join([str(item) for item in res['x']])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 375.926\n",
      "[200]\ttraining's rmse: 191.7\n",
      "[300]\ttraining's rmse: 139.17\n"
     ]
    }
   ],
   "source": [
    "# 重新训练一次模型，使用11月全部数据\n",
    "d_train = lgb.Dataset(train.loc[train.month.isin([11]), features], label=train.loc[train.month.isin([11])].num.values)\n",
    "watchlist = [d_train]\n",
    "model = lgb.train(lgb_params, train_set=d_train, num_boost_round=300, valid_sets=watchlist, \\\n",
    "early_stopping_rounds=None, verbose_eval=100)\n",
    "\n",
    "rf.fit(train.loc[train.month.isin([11]), features], \\\n",
    "       train.loc[train.month.isin([11])].num.values)\n",
    "gbm.fit(train.loc[train.month.isin([11]), features], \\\n",
    "        train.loc[train.month.isin([11])].num.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_data_12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['hour'] = test.time_stamp.apply(lambda x: int(x[-2:]))\n",
    "test['month'] = test.time_stamp.apply(lambda x: int(x.split('-')[1]))\n",
    "test['day'] = test.time_stamp.apply(lambda x: int(x.split('-')[2][:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['dayofweek'] = pd.DatetimeIndex(test.time_stamp).dayofweek\n",
    "test['isweekend'] = test['dayofweek'].apply(lambda x: 1 if x==5 or x==6 else 0)\n",
    "test['isweekday'] = 1 - test['isweekend']\n",
    "test['ymd'] = test.time_stamp.apply(lambda x: x[:10])\n",
    "test = pd.merge(test, weather, on='ymd', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test,\\\n",
    "                train.loc[train.month.isin([10,11])].groupby(['loc_id', 'hour']).apply(getmean).reset_index().rename(columns={0:'loc_hour_mean'}),\\\n",
    "                on=['loc_id', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test,\\\n",
    "                train.loc[train.month.isin([10,11])].groupby(['loc_id', 'dayofweek', 'hour']).apply(getmean).reset_index().rename(columns={0:'loc_week_hour_mean'}),\\\n",
    "                on=['loc_id', 'dayofweek', 'hour'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hour_bins = [-1, 6, 19, 23]\n",
    "test['hour_cut'] = pd.cut(test.hour, hour_bins, labels=False)\n",
    "day_bins = [0, 10, 20, 31]\n",
    "test['day_cut'] = pd.cut(test.day, day_bins, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['loc_type'] = 0\n",
    "test.loc[test['loc_id'].isin([8,10,12,29]),'loc_type'] = 1\n",
    "test.loc[test['loc_id'].isin([16,33,27,15,22,24,14,20]),'loc_type'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rule_ans_test = train.loc[train.month.isin([10,11])].groupby(['loc_id', 'dayofweek', 'hour']).\\\n",
    "apply(getmean).reset_index().rename(columns={0:'num_1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rule_res = \\\n",
    "pd.merge(test, rule_ans_test, on=['loc_id','dayofweek','hour'], how='left')['num_1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.22 s, sys: 36 ms, total: 2.25 s\n",
      "Wall time: 846 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test['num_of_people'] = \\\n",
    "weights_list[-1][0] * model.predict(test[features]) +\\\n",
    "weights_list[-1][1] * rf.predict(test[features]) +\\\n",
    "weights_list[-1][2] * gbm.predict(test[features]) +\\\n",
    "weights_list[-1][3] * rule_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['loc_id', 'time_stamp', 'num_of_people']].to_csv('submit/submit_gbm_normal_lgb.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
