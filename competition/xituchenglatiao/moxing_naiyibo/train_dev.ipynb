{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/.local/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "/home/zhangqq/.local/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 191.07\tvalid_0's mse: 191.07\n",
      "[200]\tvalid_0's rmse: 111.668\tvalid_0's mse: 111.668\n",
      "[300]\tvalid_0's rmse: 98.2631\tvalid_0's mse: 98.2631\n",
      "[400]\tvalid_0's rmse: 97.5313\tvalid_0's mse: 97.5313\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's rmse: 97.3411\tvalid_0's mse: 97.3411\n",
      "data_mean_week_hour      3517\n",
      "data_max_week_hour       2916\n",
      "data_min_week_hour       2078\n",
      "data_median_week_hour    1397\n",
      "pressure                  978\n",
      "hour_rate                 891\n",
      "NO2                       860\n",
      "loc_rate                  826\n",
      "O3_8h                     811\n",
      "humidity                  657\n",
      "loc_week                  627\n",
      "SSD                       622\n",
      "temperature               541\n",
      "week_num                  468\n",
      "PM10                      466\n",
      "week_rate                 465\n",
      "AQI                       403\n",
      "SO2                       368\n",
      "wind_speed                361\n",
      "hour_weather              310\n",
      "loc_weather               298\n",
      "CO                        288\n",
      "loc_id                    287\n",
      "hour_week                 272\n",
      "PM2.5                     270\n",
      "week_weather              260\n",
      "hour                      221\n",
      "loc_hour                  218\n",
      "rate_weather              106\n",
      "week                       41\n",
      "rate                       29\n",
      "holiday                    20\n",
      "weather                    17\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from dateutil.parser import parse\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "train = pd.read_csv('./chouchoukan.csv')\n",
    "dev = pd.read_csv('./chouchoukan_dev.csv')\n",
    "\n",
    "# train = train.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# test = test.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# print(train['holiday'])\n",
    "# del test['holiday']\n",
    "# del dev['holiday']\n",
    "# del train['holiday']\n",
    "# train = train.astype('float64')\n",
    "predictors = [f for f in train.columns if f not in ['phone_num','time_stamp','wind_v','wind_u']]\n",
    "\n",
    "def evalerror(pred, df):\n",
    "    label = df.get_label().values.copy()\n",
    "    score = math.sqrt(mean_squared_error(label,pred))\n",
    "    return ('mse',score,False)\n",
    "\n",
    "print('Training..')\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split  \n",
    "# train_feat, val_feat, train_y, val_y = train_test_split(train[predictors],train['phone_num'],test_size = 0.2,random_state=42) \n",
    "train_feat = train[predictors]\n",
    "train_y = train['phone_num']\n",
    "\n",
    "val_feat = dev[predictors]\n",
    "val_y = dev['phone_num']\n",
    "lgb_train = lgb.Dataset(train_feat, train_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "lgb_val = lgb.Dataset(val_feat, val_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=50000,\n",
    "                valid_sets=lgb_val,\n",
    "                verbose_eval=100,\n",
    "                feval=evalerror,\n",
    "                early_stopping_rounds=100)\n",
    "print(pd.Series(gbm.feature_importance(),index = predictors).sort_values(ascending = False))\n",
    "# import pickle\n",
    "# with open('gbm_pm25_ld.pkl', 'wb') as f:\n",
    "#     pickle.dump(gbm, f)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/.local/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 208.35\ttraining's mse: 208.35\n",
      "[200]\ttraining's rmse: 127.519\ttraining's mse: 127.519\n",
      "[300]\ttraining's rmse: 104.386\ttraining's mse: 104.386\n",
      "data_mean_week_hour      3592\n",
      "data_max_week_hour       1898\n",
      "data_median_week_hour    1383\n",
      "loc_rate                 1361\n",
      "data_min_week_hour       1279\n",
      "loc_week                 1271\n",
      "O3_8h                    1079\n",
      "hour_rate                1051\n",
      "week_num                  907\n",
      "week_rate                 823\n",
      "NO2                       664\n",
      "humidity                  589\n",
      "pressure                  587\n",
      "SSD                       557\n",
      "temperature               546\n",
      "PM10                      530\n",
      "loc_hour                  528\n",
      "PM2.5                     491\n",
      "loc_weather               425\n",
      "AQI                       351\n",
      "hour_week                 318\n",
      "SO2                       280\n",
      "hour_weather              262\n",
      "CO                        258\n",
      "wind_speed                251\n",
      "loc_id                    217\n",
      "week_weather              144\n",
      "hour                      136\n",
      "rate_weather               70\n",
      "holiday                    22\n",
      "week                       16\n",
      "rate                        2\n",
      "weather                     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from dateutil.parser import parse\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "train = pd.read_csv('./chouchoukan2.csv')\n",
    "\n",
    "test = pd.read_csv('./test_X.csv')\n",
    "# train = train.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# test = test.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# print(train['holiday'])\n",
    "# del test['holiday']\n",
    "\n",
    "# del train['holiday']\n",
    "# train = train.astype('float64')\n",
    "predictors = [f for f in train.columns if f not in ['phone_num','time_stamp','wind_v','wind_u']]\n",
    "\n",
    "def evalerror(pred, df):\n",
    "    label = df.get_label().values.copy()\n",
    "    score = math.sqrt(mean_squared_error(label,pred))\n",
    "    return ('mse',score,False)\n",
    "\n",
    "print('Training..')\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split  \n",
    "# train_feat, val_feat, train_y, val_y = train_test_split(train[predictors],train['phone_num'],test_size = 0.2,random_state=42) \n",
    "train_feat = train[predictors]\n",
    "train_y = train['phone_num']\n",
    "\n",
    "# val_feat = dev[predictors]\n",
    "# val_y = dev['phone_num']\n",
    "lgb_train = lgb.Dataset(train_feat, train_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "# lgb_val = lgb.Dataset(val_feat, val_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=371,\n",
    "                valid_sets=lgb_train,\n",
    "                verbose_eval=100,\n",
    "                feval=evalerror,\n",
    "                )\n",
    "print(pd.Series(gbm.feature_importance(),index = predictors).sort_values(ascending = False))\n",
    "# import pickle\n",
    "# with open('gbm_pm25_ld.pkl', 'wb') as f:\n",
    "#     pickle.dump(gbm, f)\n",
    "test_x = test[['loc_id','time_stamp']]\n",
    "\n",
    "\n",
    "test_x['time_stamp'] = test_x['time_stamp'].apply(lambda x: x.split(':')[0])  \n",
    "\n",
    "\n",
    "test_y = gbm.predict(test[predictors])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_y = pd.DataFrame(test_y)\n",
    "test_y.columns = ['num_of_people']\n",
    "test_y['num_of_people'] = test_y['num_of_people'].astype('int32')\n",
    "data = pd.concat([test_x, test_y],axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "data['num_of_people'][data['num_of_people']<=0] = 20\n",
    "data.to_csv('submit.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "path_to_bj_aq = \"./data/month456/test/\"\n",
    "\n",
    "bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "\n",
    "for csv in bj_csv_list :\n",
    "    if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "        path_to_file = path_to_bj_aq + csv\n",
    "        \n",
    "        data = pd.read_csv(path_to_file)\n",
    "        i = csv.split('.')[0]\n",
    "\n",
    "        data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "        data = data.groupby(['time_stamp','loc_id'],as_index = False).count()\n",
    "        data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "        data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "        data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "        for j in range(1,34):\n",
    "            data_part = data[data['loc_id'] == j]\n",
    "            mkdir('./datatest/station_%s' % (j))\n",
    "            data_part.to_csv('datatest/station_%s/month_%s.csv' % (j,i),index = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "#数据预处理\n",
    "\n",
    "\n",
    "# data_meo = pd.read_csv('data/data_meo.csv')   \n",
    "datas = []\n",
    "for i in range(1,34):\n",
    "    path_to_bj_aq = \"./datatest/station_\"+str(i)+\"/\"\n",
    "\n",
    "    bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    \n",
    "    for csv in bj_csv_list :\n",
    "        if csv != '.DS_Store' and not csv.startswith(\"._\") :\n",
    "            \n",
    "            path_to_file = path_to_bj_aq + csv\n",
    "            data = pd.read_csv(path_to_file)  \n",
    "            if data.empty == False:\n",
    "                datas.append(data)\n",
    "\n",
    "data_all = pd.concat(datas, ignore_index=True)\n",
    "\n",
    "\n",
    "# data_all = pd.merge(data_all, data_meo, how='left', on=['time_stamp'])\n",
    "data_all.rename(index=str, columns={\"phone_id\": \"num_of_people\"},inplace = True)\n",
    "\n",
    "data_all = data_all[['loc_id','time_stamp',\"num_of_people\"]]\n",
    "\n",
    "\n",
    "data_all['time_stamp'] = data_all['time_stamp'].apply(lambda x: x.split(':')[0])  \n",
    "\n",
    "\n",
    "\n",
    "data_all.to_csv('submit0.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157.20776240937306\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./submit.csv')\n",
    "dev = pd.read_csv('./submit0.csv')\n",
    "data = pd.merge(train, dev, how='inner', on=['time_stamp','loc_id'])\n",
    "\n",
    "score = math.sqrt(mean_squared_error(data['num_of_people_x'],data['num_of_people_y']))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
