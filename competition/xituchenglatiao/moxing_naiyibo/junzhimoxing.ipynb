{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#junzhimoxing\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "def mkdir(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "path_to_bj_aq = \"./data/months1_10/\"\n",
    "\n",
    "bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "\n",
    "for csv in bj_csv_list :\n",
    "    if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "        path_to_file = path_to_bj_aq + csv\n",
    "        \n",
    "        data = pd.read_csv(path_to_file)\n",
    "        i = csv.split('.')[0]\n",
    "\n",
    "        data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "        data = data.groupby(['time_stamp','loc_id'],as_index = False).count()\n",
    "        data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "        data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "        data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "        for j in range(1,34):\n",
    "            data_part = data[data['loc_id'] == j]\n",
    "            mkdir('./data/station_%s' % (j))\n",
    "            data_part.to_csv('data/station_%s/month_%s.csv' % (j,i),index = False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "min_time = datetime.datetime.strptime('2017-12-01 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "max_time = datetime.datetime.strptime('2017-12-31 23:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "delta_all = max_time - min_time\n",
    "hours_should = delta_all.total_seconds()/3600 + 1\n",
    "delta = datetime.timedelta(hours=1)\n",
    "time = min_time\n",
    "\n",
    "time_stamp = []\n",
    "loc_id = []\n",
    "while time <=  max_time :\n",
    "    \n",
    "    for i in range(1,34):\n",
    "        time_stamp.append(time)\n",
    "        loc_id.append(i)\n",
    "    time += delta\n",
    "data['time_stamp'] = time_stamp\n",
    "data['loc_id'] = loc_id\n",
    "\n",
    "\n",
    "data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "holiday = pd.read_csv('data/holiday.csv')\n",
    "data = pd.merge(data, holiday, how='inner', on=['date'])\n",
    "data['holiday'][data['holiday'] == 2] = 1\n",
    "# data['data_mean'] = 0\n",
    "# data['data_max'] = 0\n",
    "# data['data_min']= 0\n",
    "# data['data_median'] = 0\n",
    "\n",
    "# # data['data_mean_hour'] = 0\n",
    "# # data['data_max_hour'] = 0\n",
    "# # data['data_min_hour']= 0\n",
    "# data['data_median_hour'] = 0\n",
    "\n",
    "# # data['data_mean_week'] = 0\n",
    "# # data['data_max_week'] = 0\n",
    "# # data['data_min_week']= 0\n",
    "# data['data_median_week'] = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data['data_mean_week_hour'] = 0\n",
    "# data['data_max_week_hour'] = 0\n",
    "# data['data_min_week_hour']= 0\n",
    "data['data_median_week_hour'] = 0\n",
    "data['data_var_week_hour'] = 0\n",
    "datas = []\n",
    "for i in range(1,34):\n",
    "    path_to_bj_aq = \"./data/station_\"+str(i)+\"/\"\n",
    "\n",
    "    bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    for csv in bj_csv_list :\n",
    "        if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "            path_to_file = path_to_bj_aq + csv\n",
    "            data_su = pd.read_csv(path_to_file)\n",
    "            if data_su.empty == False:\n",
    "                datas.append(data_su)\n",
    "\n",
    "data_all = pd.concat(datas, ignore_index=True)\n",
    "data_all.rename(index=str, columns={\"phone_id\": \"phone_num\"},inplace = True)\n",
    "\n",
    "# for i in range(1,34):    \n",
    "#     data_mean = data_all['phone_num'][data_all['loc_id'] == i].mean()\n",
    "#     data_max = data_all['phone_num'][data_all['loc_id'] == i].max()\n",
    "#     data_min = data_all['phone_num'][data_all['loc_id'] == i].min()\n",
    "#     data_median = data_all['phone_num'][data_all['loc_id'] == i].median()\n",
    "    \n",
    "#     data['data_mean'][data['loc_id'] == i] = data_mean\n",
    "#     data['data_max'][data['loc_id'] == i] = data_max\n",
    "#     data['data_min'][data['loc_id'] == i] = data_min\n",
    "#     data['data_median'][data['loc_id'] == i] = data_median\n",
    "        \n",
    "for i in range(1,34):\n",
    "    for h in range(24):   \n",
    "        for j in range(7):\n",
    "            data_mean = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "#             data_max = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "#             data_min = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "            data_median = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "            data_var = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].var()\n",
    "#             print(data_mean)\n",
    "\n",
    "            data['data_mean_week_hour'][(data['loc_id'] == i)&(data['week'] == j)&(data['hour'] == h)] = data_mean\n",
    "#             data['data_max_week_hour'][(data['loc_id'] == i)&(data['week'] == j)&(data['hour'] == h)] = data_max\n",
    "#             data['data_min_week_hour'][(data['loc_id'] == i)&(data['week'] == j)&(data['hour'] == h)] = data_min\n",
    "            data['data_median_week_hour'][(data['loc_id'] == i)&(data['week'] == j)&(data['hour'] == h)] = data_median\n",
    "            data['data_var_week_hour'][(data['loc_id'] == i)&(data['week'] == j)&(data['hour'] == h)] = data_var\n",
    "# data['time_stamp'] = data['time_stamp'].astype('str')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data.to_csv('predict12_latiao.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./predict12_latiao.csv')\n",
    "train['time_stamp'] = train['time_stamp'].apply(lambda x: x.split(':')[0])  \n",
    "train = train[['loc_id','time_stamp','data_mean_week_hour']]\n",
    "train.to_csv('submitkankan_qushang11.csv',index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./submitkankan_qushang11.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_of_people'] = train['num_of_people']*0.96\n",
    "train.to_csv('submitzqq96.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
