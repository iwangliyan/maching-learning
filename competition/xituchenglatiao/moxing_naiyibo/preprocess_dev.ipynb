{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:98: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:174: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:325: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:326: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:325: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:326: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:325: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:326: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:327: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:324: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:400: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "path_to_bj_aq = \"./data/month456/train/\"\n",
    "\n",
    "bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "\n",
    "for csv in bj_csv_list :\n",
    "    if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "        path_to_file = path_to_bj_aq + csv\n",
    "        \n",
    "        data = pd.read_csv(path_to_file)\n",
    "        i = csv.split('.')[0]\n",
    "\n",
    "        data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "        data = data.groupby(['time_stamp','loc_id'],as_index = False).count()\n",
    "        data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "        data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "        data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "        for j in range(1,34):\n",
    "            data_part = data[data['loc_id'] == j]\n",
    "            mkdir('./data/station_%s' % (j))\n",
    "            data_part.to_csv('data/station_%s/month_%s.csv' % (j,i),index = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "#数据预处理\n",
    "\n",
    "\n",
    "holiday = pd.read_csv('data/holiday.csv')          \n",
    "datas = []\n",
    "for i in range(1,34):\n",
    "    path_to_bj_aq = \"./data/station_\"+str(i)+\"/\"\n",
    "\n",
    "    bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    \n",
    "    for csv in bj_csv_list :\n",
    "        if csv != '.DS_Store' and not csv.startswith(\"._\") :\n",
    "            \n",
    "            path_to_file = path_to_bj_aq + csv\n",
    "            data = pd.read_csv(path_to_file)  \n",
    "            if data.empty == False:\n",
    "                datas.append(data)\n",
    "\n",
    "data_all = pd.concat(datas, ignore_index=True)\n",
    "\n",
    "data_all = pd.merge(data_all, holiday, how='inner', on=['date'])\n",
    "data_all = data_all[data_all['holiday']!=2]\n",
    "\n",
    "data_all.rename(index=str, columns={\"phone_id\": \"phone_num\"},inplace = True)\n",
    "\n",
    "# data_all['data_mean'] = 0\n",
    "# data_all['data_max'] = 0\n",
    "# data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "data_all['data_mean_week_hour'] = 0\n",
    "data_all['data_max_week_hour'] = 0\n",
    "data_all['data_min_week_hour']= 0\n",
    "data_all['data_median_week_hour'] = 0\n",
    "\n",
    "\n",
    "# for i in range(1,34):    \n",
    "#     data_mean = data_all['phone_num'][data_all['loc_id'] == i].mean()\n",
    "#     data_max = data_all['phone_num'][data_all['loc_id'] == i].max()\n",
    "#     data_min = data_all['phone_num'][data_all['loc_id'] == i].min()\n",
    "#     data_median = data_all['phone_num'][data_all['loc_id'] == i].median()\n",
    "    \n",
    "#     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "#     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "#     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "\n",
    "for i in range(1,34):\n",
    "    for h in range(24):   \n",
    "        for j in range(7):\n",
    "            data_mean = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "            data_max = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "            data_min = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "            data_median = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "#             data_var = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].var()\n",
    "\n",
    "\n",
    "            data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "            data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "            data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "            data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             data_all['data_var_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_var\n",
    "# # data_all['data_mean'] = 0\n",
    "# # data_all['data_max'] = 0\n",
    "# # data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "\n",
    "# # data_all['data_mean_hour'] = 0\n",
    "# # data_all['data_max_hour'] = 0\n",
    "# # data_all['data_min_hour']= 0\n",
    "# data_all['data_median_hour'] = 0\n",
    "\n",
    "# # data_all['data_mean_week'] = 0\n",
    "# # data_all['data_max_week'] = 0\n",
    "# # data_all['data_min_week']= 0\n",
    "# data_all['data_median_week'] = 0\n",
    "\n",
    "# # data_all['data_mean_week_hour'] = 0\n",
    "# # data_all['data_max_week_hour'] = 0\n",
    "# # data_all['data_min_week_hour']= 0\n",
    "# # data_all['data_median_week_hour'] = 0\n",
    "# for i in range(1,34):\n",
    "\n",
    "# #     data_mean = data_all['phone_num'].mean()\n",
    "# #     data_max = data_all['phone_num'].max()\n",
    "# #     data_min = data_all['phone_num'].min()\n",
    "#     data_median = data_all['phone_num'].median()\n",
    "    \n",
    "# #     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "# #     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "# #     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "    \n",
    "#     for j in range(24):\n",
    "# #         data_mean = data_all['phone_num'][data_all['hour'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['hour'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['hour'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['hour'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_mean\n",
    "# #         data_all['data_max_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_max\n",
    "# #         data_all['data_min_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_min\n",
    "#         data_all['data_median_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_median\n",
    "        \n",
    "#     for j in range(7):\n",
    "# #         data_mean = data_all['phone_num'][data_all['week'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['week'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['week'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['week'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_mean\n",
    "# #         data_all['data_max_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_max\n",
    "# #         data_all['data_min_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_min\n",
    "#         data_all['data_median_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_median\n",
    "#     for h in range(24):   \n",
    "#         for j in range(7):\n",
    "# #             data_mean = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "# #             data_max = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "# #             data_min = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "#             data_median = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "\n",
    "# #             data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "# #             data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "# #             data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "#             data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "    \n",
    "data_all.to_csv('data/data_all.csv',index = False)         \n",
    "            \n",
    "#处理meo            \n",
    "data_meo = pd.read_csv('data/beijing_17_18_meo.csv')\n",
    "\n",
    "data_meo['wind_speed'][data_meo['wind_direction'] == 999017] = 0.1\n",
    "data_meo['wind_u'] = data_meo['wind_speed']*np.cos(data_meo['wind_direction'])\n",
    "data_meo['wind_v'] = data_meo['wind_speed']*np.sin(data_meo['wind_direction'])\n",
    "\n",
    "data_meo['weather'].replace(['Fog','Haze','Rain','Sunny/clear'],[1,2,3,4],inplace=True)\n",
    "\n",
    "data_meo['SSD'] = (1.818*data_meo['temperature']+18.18)*(0.88+0.002*data_meo['humidity'])+(data_meo['temperature']-32)/(45-data_meo['temperature'])-3.2*data_meo['wind_speed']+18.2\n",
    "del data_meo['wind_direction']         \n",
    "data_meo.to_csv('data/data_meo.csv',index = False)      \n",
    "\n",
    "#处理aq\n",
    "data_aq = pd.read_csv('data/aq_beifen.csv')\n",
    "data_aq['rate'].replace(['重度污染','严重污染','中度污染','轻度污染','良','优'],[1,2,3,4,5,6],inplace=True)\n",
    "data_aq.to_csv('data/data_aq.csv',index = False)  \n",
    "\n",
    "#合并数据\n",
    "data_aq = pd.read_csv('data/data_aq.csv')\n",
    "data_meo = pd.read_csv('data/data_meo.csv')\n",
    "data_base = pd.read_csv('data/data_all.csv')\n",
    "# print(data_base.isnull().sum())\n",
    "# print(data_base.columns.size)\n",
    "# print(data_base.iloc[:,0].size)\n",
    "# print(data_meo.columns.size)\n",
    "# print(data_meo.iloc[:,0].size)\n",
    "data = pd.merge(data_base, data_meo, how='inner', on=['time_stamp'])\n",
    "data = pd.merge(data, data_aq, how='inner', on=['date'])\n",
    "# print(data.columns.size)\n",
    "# print(data.iloc[:,0].size)\n",
    "\n",
    "\n",
    "\n",
    "data['loc_hour'] = data['loc_id']*100+data['hour']\n",
    "data['loc_week'] = data['loc_id']*100+data['week']\n",
    "data['loc_rate'] = data['loc_id']*100+data['rate']\n",
    "data['loc_weather'] = data['loc_id']*100+data['weather']\n",
    "\n",
    "# data_all['week_num_percent'] = data_all['week_num']/20\n",
    "# data['loc_week_num'] = data['loc_id']*100+data['week_num']\n",
    "\n",
    "data['hour_rate'] = data['hour']*100+data['rate']\n",
    "data['hour_weather'] = data['hour']*100+data['weather']\n",
    "data['hour_week'] = data['hour']*100+data['rate']\n",
    "\n",
    "data['week_rate'] = data['week']*100+data['rate']\n",
    "data['week_weather'] = data['week']*100+data['weather']\n",
    "\n",
    "data['rate_weather'] = data['rate']*100+data['weather']\n",
    "del data['date']\n",
    "data.to_csv('chouchoukan.csv',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "path_to_bj_aq = \"./data/month456/dev/\"\n",
    "\n",
    "bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "\n",
    "for csv in bj_csv_list :\n",
    "    if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "        path_to_file = path_to_bj_aq + csv\n",
    "        \n",
    "        data = pd.read_csv(path_to_file)\n",
    "        i = csv.split('.')[0]\n",
    "\n",
    "        data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "        data = data.groupby(['time_stamp','loc_id'],as_index = False).count()\n",
    "        data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "        data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "        data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "        for j in range(1,34):\n",
    "            data_part = data[data['loc_id'] == j]\n",
    "            mkdir('./data_dev/station_%s' % (j))\n",
    "            data_part.to_csv('data_dev/station_%s/month_%s.csv' % (j,i),index = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "#数据预处理\n",
    "\n",
    "\n",
    "holiday = pd.read_csv('data/holiday.csv')          \n",
    "datas = []\n",
    "for i in range(1,34):\n",
    "    path_to_bj_aq = \"./data_dev/station_\"+str(i)+\"/\"\n",
    "\n",
    "    bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    \n",
    "    for csv in bj_csv_list :\n",
    "        if csv != '.DS_Store' and not csv.startswith(\"._\") :\n",
    "            \n",
    "            path_to_file = path_to_bj_aq + csv\n",
    "            data = pd.read_csv(path_to_file)  \n",
    "            if data.empty == False:\n",
    "                datas.append(data)\n",
    "\n",
    "data_all = pd.concat(datas, ignore_index=True)\n",
    "\n",
    "data_all = pd.merge(data_all, holiday, how='inner', on=['date'])\n",
    "data_all = data_all[data_all['holiday']!=2]\n",
    "\n",
    "data_all.rename(index=str, columns={\"phone_id\": \"phone_num\"},inplace = True)\n",
    "\n",
    "# data_all['data_mean'] = 0\n",
    "# data_all['data_max'] = 0\n",
    "# data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "data_all['data_mean_week_hour'] = 0\n",
    "data_all['data_max_week_hour'] = 0\n",
    "data_all['data_min_week_hour']= 0\n",
    "data_all['data_median_week_hour'] = 0\n",
    "\n",
    "\n",
    "# for i in range(1,34):    \n",
    "#     data_mean = data_all['phone_num'][data_all['loc_id'] == i].mean()\n",
    "#     data_max = data_all['phone_num'][data_all['loc_id'] == i].max()\n",
    "#     data_min = data_all['phone_num'][data_all['loc_id'] == i].min()\n",
    "#     data_median = data_all['phone_num'][data_all['loc_id'] == i].median()\n",
    "    \n",
    "#     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "#     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "#     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "\n",
    "for i in range(1,34):\n",
    "    for h in range(24):   \n",
    "        for j in range(7):\n",
    "            data_mean = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "            data_max = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "            data_min = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "            data_median = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "#             data_var = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].var()\n",
    "\n",
    "\n",
    "            data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "            data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "            data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "            data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "\n",
    "\n",
    "#             data_all['data_var_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_var\n",
    "# # data_all['data_mean'] = 0\n",
    "# # data_all['data_max'] = 0\n",
    "# # data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "\n",
    "# # data_all['data_mean_hour'] = 0\n",
    "# # data_all['data_max_hour'] = 0\n",
    "# # data_all['data_min_hour']= 0\n",
    "# data_all['data_median_hour'] = 0\n",
    "\n",
    "# # data_all['data_mean_week'] = 0\n",
    "# # data_all['data_max_week'] = 0\n",
    "# # data_all['data_min_week']= 0\n",
    "# data_all['data_median_week'] = 0\n",
    "\n",
    "# # data_all['data_mean_week_hour'] = 0\n",
    "# # data_all['data_max_week_hour'] = 0\n",
    "# # data_all['data_min_week_hour']= 0\n",
    "# # data_all['data_median_week_hour'] = 0\n",
    "# for i in range(1,34):\n",
    "\n",
    "# #     data_mean = data_all['phone_num'].mean()\n",
    "# #     data_max = data_all['phone_num'].max()\n",
    "# #     data_min = data_all['phone_num'].min()\n",
    "#     data_median = data_all['phone_num'].median()\n",
    "    \n",
    "# #     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "# #     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "# #     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "    \n",
    "#     for j in range(24):\n",
    "# #         data_mean = data_all['phone_num'][data_all['hour'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['hour'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['hour'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['hour'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_mean\n",
    "# #         data_all['data_max_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_max\n",
    "# #         data_all['data_min_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_min\n",
    "#         data_all['data_median_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_median\n",
    "        \n",
    "#     for j in range(7):\n",
    "# #         data_mean = data_all['phone_num'][data_all['week'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['week'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['week'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['week'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_mean\n",
    "# #         data_all['data_max_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_max\n",
    "# #         data_all['data_min_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_min\n",
    "#         data_all['data_median_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_median\n",
    "#     for h in range(24):   \n",
    "#         for j in range(7):\n",
    "# #             data_mean = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "# #             data_max = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "# #             data_min = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "#             data_median = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "\n",
    "# #             data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "# #             data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "# #             data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "#             data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "    \n",
    "data_all.to_csv('data/data_all_dev.csv',index = False)         \n",
    "            \n",
    "#处理meo            \n",
    "data_meo = pd.read_csv('data/beijing_17_18_meo.csv')\n",
    "\n",
    "data_meo['wind_speed'][data_meo['wind_direction'] == 999017] = 0.1\n",
    "data_meo['wind_u'] = data_meo['wind_speed']*np.cos(data_meo['wind_direction'])\n",
    "data_meo['wind_v'] = data_meo['wind_speed']*np.sin(data_meo['wind_direction'])\n",
    "\n",
    "data_meo['weather'].replace(['Fog','Haze','Rain','Sunny/clear'],[1,2,3,4],inplace=True)\n",
    "\n",
    "data_meo['SSD'] = (1.818*data_meo['temperature']+18.18)*(0.88+0.002*data_meo['humidity'])+(data_meo['temperature']-32)/(45-data_meo['temperature'])-3.2*data_meo['wind_speed']+18.2\n",
    "del data_meo['wind_direction']         \n",
    "data_meo.to_csv('data/data_meo.csv',index = False)      \n",
    "\n",
    "#处理aq\n",
    "data_aq = pd.read_csv('data/aq_beifen.csv')\n",
    "data_aq['rate'].replace(['重度污染','严重污染','中度污染','轻度污染','良','优'],[1,2,3,4,5,6],inplace=True)\n",
    "data_aq.to_csv('data/data_aq.csv',index = False)  \n",
    "\n",
    "#合并数据\n",
    "data_aq = pd.read_csv('data/data_aq.csv')\n",
    "data_meo = pd.read_csv('data/data_meo.csv')\n",
    "data_base = pd.read_csv('data/data_all_dev.csv')\n",
    "# print(data_base.isnull().sum())\n",
    "# print(data_base.columns.size)\n",
    "# print(data_base.iloc[:,0].size)\n",
    "# print(data_meo.columns.size)\n",
    "# print(data_meo.iloc[:,0].size)\n",
    "data = pd.merge(data_base, data_meo, how='inner', on=['time_stamp'])\n",
    "data = pd.merge(data, data_aq, how='inner', on=['date'])\n",
    "# print(data.columns.size)\n",
    "# print(data.iloc[:,0].size)\n",
    "\n",
    "\n",
    "\n",
    "data['loc_hour'] = data['loc_id']*100+data['hour']\n",
    "data['loc_week'] = data['loc_id']*100+data['week']\n",
    "data['loc_rate'] = data['loc_id']*100+data['rate']\n",
    "data['loc_weather'] = data['loc_id']*100+data['weather']\n",
    "\n",
    "# data_all['week_num_percent'] = data_all['week_num']/20\n",
    "# data['loc_week_num'] = data['loc_id']*100+data['week_num']\n",
    "\n",
    "data['hour_rate'] = data['hour']*100+data['rate']\n",
    "data['hour_weather'] = data['hour']*100+data['weather']\n",
    "data['hour_week'] = data['hour']*100+data['rate']\n",
    "\n",
    "data['week_rate'] = data['week']*100+data['rate']\n",
    "data['week_weather'] = data['week']*100+data['weather']\n",
    "\n",
    "data['rate_weather'] = data['rate']*100+data['weather']\n",
    "del data['date']\n",
    "data.to_csv('chouchoukan_dev.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#第二轮用了45月份数据\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "path_to_bj_aq = \"./data/month456/train_2/\"\n",
    "\n",
    "bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "\n",
    "for csv in bj_csv_list :\n",
    "    if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "        path_to_file = path_to_bj_aq + csv\n",
    "        \n",
    "        data = pd.read_csv(path_to_file)\n",
    "        i = csv.split('.')[0]\n",
    "\n",
    "        data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "        data = data.groupby(['time_stamp','loc_id'],as_index = False).count()\n",
    "        data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "        data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "        data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "        for j in range(1,34):\n",
    "            data_part = data[data['loc_id'] == j]\n",
    "            mkdir('./data2/station_%s' % (j))\n",
    "            data_part.to_csv('data2/station_%s/month_%s.csv' % (j,i),index = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "#数据预处理\n",
    "\n",
    "\n",
    "holiday = pd.read_csv('data/holiday.csv')          \n",
    "datas = []\n",
    "for i in range(1,34):\n",
    "    path_to_bj_aq = \"./data2/station_\"+str(i)+\"/\"\n",
    "\n",
    "    bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    \n",
    "    for csv in bj_csv_list :\n",
    "        if csv != '.DS_Store' and not csv.startswith(\"._\") :\n",
    "            \n",
    "            path_to_file = path_to_bj_aq + csv\n",
    "            data = pd.read_csv(path_to_file)  \n",
    "            if data.empty == False:\n",
    "                datas.append(data)\n",
    "\n",
    "data_all = pd.concat(datas, ignore_index=True)\n",
    "\n",
    "data_all = pd.merge(data_all, holiday, how='inner', on=['date'])\n",
    "data_all = data_all[data_all['holiday']!=2]\n",
    "\n",
    "data_all.rename(index=str, columns={\"phone_id\": \"phone_num\"},inplace = True)\n",
    "\n",
    "# data_all['data_mean'] = 0\n",
    "# data_all['data_max'] = 0\n",
    "# data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "data_all['data_mean_week_hour'] = 0\n",
    "data_all['data_max_week_hour'] = 0\n",
    "data_all['data_min_week_hour']= 0\n",
    "data_all['data_median_week_hour'] = 0\n",
    "\n",
    "\n",
    "# for i in range(1,34):    \n",
    "#     data_mean = data_all['phone_num'][data_all['loc_id'] == i].mean()\n",
    "#     data_max = data_all['phone_num'][data_all['loc_id'] == i].max()\n",
    "#     data_min = data_all['phone_num'][data_all['loc_id'] == i].min()\n",
    "#     data_median = data_all['phone_num'][data_all['loc_id'] == i].median()\n",
    "    \n",
    "#     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "#     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "#     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "\n",
    "for i in range(1,34):\n",
    "    for h in range(24):   \n",
    "        for j in range(7):\n",
    "            data_mean = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "            data_max = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "            data_min = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "            data_median = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "#             data_var = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].var()\n",
    "\n",
    "\n",
    "            data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "            data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "            data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "            data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#             data_all['data_var_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_var\n",
    "# # data_all['data_mean'] = 0\n",
    "# # data_all['data_max'] = 0\n",
    "# # data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "\n",
    "# # data_all['data_mean_hour'] = 0\n",
    "# # data_all['data_max_hour'] = 0\n",
    "# # data_all['data_min_hour']= 0\n",
    "# data_all['data_median_hour'] = 0\n",
    "\n",
    "# # data_all['data_mean_week'] = 0\n",
    "# # data_all['data_max_week'] = 0\n",
    "# # data_all['data_min_week']= 0\n",
    "# data_all['data_median_week'] = 0\n",
    "\n",
    "# # data_all['data_mean_week_hour'] = 0\n",
    "# # data_all['data_max_week_hour'] = 0\n",
    "# # data_all['data_min_week_hour']= 0\n",
    "# # data_all['data_median_week_hour'] = 0\n",
    "# for i in range(1,34):\n",
    "\n",
    "# #     data_mean = data_all['phone_num'].mean()\n",
    "# #     data_max = data_all['phone_num'].max()\n",
    "# #     data_min = data_all['phone_num'].min()\n",
    "#     data_median = data_all['phone_num'].median()\n",
    "    \n",
    "# #     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "# #     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "# #     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "    \n",
    "#     for j in range(24):\n",
    "# #         data_mean = data_all['phone_num'][data_all['hour'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['hour'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['hour'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['hour'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_mean\n",
    "# #         data_all['data_max_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_max\n",
    "# #         data_all['data_min_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_min\n",
    "#         data_all['data_median_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_median\n",
    "        \n",
    "#     for j in range(7):\n",
    "# #         data_mean = data_all['phone_num'][data_all['week'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['week'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['week'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['week'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_mean\n",
    "# #         data_all['data_max_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_max\n",
    "# #         data_all['data_min_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_min\n",
    "#         data_all['data_median_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_median\n",
    "#     for h in range(24):   \n",
    "#         for j in range(7):\n",
    "# #             data_mean = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "# #             data_max = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "# #             data_min = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "#             data_median = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "\n",
    "# #             data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "# #             data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "# #             data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "#             data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "    \n",
    "data_all.to_csv('data2/data_all.csv',index = False)         \n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#合并数据\n",
    "data_aq = pd.read_csv('data/data_aq.csv')\n",
    "data_meo = pd.read_csv('data/data_meo.csv')\n",
    "data_base = pd.read_csv('data2/data_all.csv')\n",
    "# print(data_base.isnull().sum())\n",
    "# print(data_base.columns.size)\n",
    "# print(data_base.iloc[:,0].size)\n",
    "# print(data_meo.columns.size)\n",
    "# print(data_meo.iloc[:,0].size)\n",
    "data = pd.merge(data_base, data_meo, how='inner', on=['time_stamp'])\n",
    "data = pd.merge(data, data_aq, how='inner', on=['date'])\n",
    "# print(data.columns.size)\n",
    "# print(data.iloc[:,0].size)\n",
    "\n",
    "\n",
    "\n",
    "data['loc_hour'] = data['loc_id']*100+data['hour']\n",
    "data['loc_week'] = data['loc_id']*100+data['week']\n",
    "data['loc_rate'] = data['loc_id']*100+data['rate']\n",
    "data['loc_weather'] = data['loc_id']*100+data['weather']\n",
    "\n",
    "# data_all['week_num_percent'] = data_all['week_num']/20\n",
    "# data['loc_week_num'] = data['loc_id']*100+data['week_num']\n",
    "\n",
    "data['hour_rate'] = data['hour']*100+data['rate']\n",
    "data['hour_weather'] = data['hour']*100+data['weather']\n",
    "data['hour_week'] = data['hour']*100+data['rate']\n",
    "\n",
    "data['week_rate'] = data['week']*100+data['rate']\n",
    "data['week_weather'] = data['week']*100+data['weather']\n",
    "\n",
    "data['rate_weather'] = data['rate']*100+data['weather']\n",
    "del data['date']\n",
    "data.to_csv('chouchoukan2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
