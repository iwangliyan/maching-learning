{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def mkdir(path):\n",
    "    isExists=os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makedirs(path) \n",
    "\n",
    "\n",
    "path_to_bj_aq = \"./data/months1_10/\"\n",
    "\n",
    "bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "\n",
    "for csv in bj_csv_list :\n",
    "    if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "        path_to_file = path_to_bj_aq + csv\n",
    "        \n",
    "        data = pd.read_csv(path_to_file)\n",
    "        i = csv.split('.')[0]\n",
    "\n",
    "        data['time_stamp'] = pd.to_datetime(data['time_stamp'])\n",
    "        data = data.groupby(['time_stamp','loc_id'],as_index = False).count()\n",
    "        data['date'] = data['time_stamp'].apply(lambda x:str(x)[:10])\n",
    "        data['hour'] = data['time_stamp'].apply(lambda x:int(str(x)[11:13]))\n",
    "        data['week'] = data['time_stamp'].apply(lambda x:x.weekday())\n",
    "\n",
    "        for j in range(1,34):\n",
    "            data_part = data[data['loc_id'] == j]\n",
    "            mkdir('./data/station_%s' % (j))\n",
    "            data_part.to_csv('data/station_%s/month_%s.csv' % (j,i),index = False)\n",
    "            \n",
    "            \n",
    "            \n",
    "#数据预处理\n",
    "\n",
    "\n",
    "holiday = pd.read_csv('data/holiday.csv')          \n",
    "datas = []\n",
    "for i in range(1,34):\n",
    "    path_to_bj_aq = \"./data/station_\"+str(i)+\"/\"\n",
    "\n",
    "    bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    \n",
    "    for csv in bj_csv_list :\n",
    "        if csv != '.DS_Store' and not csv.startswith(\"._\") :\n",
    "            \n",
    "            path_to_file = path_to_bj_aq + csv\n",
    "            data = pd.read_csv(path_to_file)  \n",
    "            if data.empty == False:\n",
    "                datas.append(data)\n",
    "\n",
    "data_all = pd.concat(datas, ignore_index=True)\n",
    "\n",
    "data_all = pd.merge(data_all, holiday, how='inner', on=['date'])\n",
    "data_all = data_all[data_all['holiday']!=2]\n",
    "\n",
    "data_all.rename(index=str, columns={\"phone_id\": \"phone_num\"},inplace = True)\n",
    "\n",
    "data_all['data_mean'] = 0\n",
    "data_all['data_max'] = 0\n",
    "data_all['data_min']= 0\n",
    "data_all['data_median'] = 0\n",
    "# data_all['data_mean_week_hour'] = 0\n",
    "# data_all['data_max_week_hour'] = 0\n",
    "# data_all['data_min_week_hour']= 0\n",
    "# data_all['data_median_week_hour'] = 0\n",
    "\n",
    "\n",
    "for i in range(1,34):    \n",
    "    data_mean = data_all['phone_num'][data_all['loc_id'] == i].mean()\n",
    "    data_max = data_all['phone_num'][data_all['loc_id'] == i].max()\n",
    "    data_min = data_all['phone_num'][data_all['loc_id'] == i].min()\n",
    "    data_median = data_all['phone_num'][data_all['loc_id'] == i].median()\n",
    "    \n",
    "    data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "    data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "    data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "    data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "\n",
    "# for i in range(1,34):\n",
    "#     for h in range(24):   \n",
    "#         for j in range(7):\n",
    "#             data_mean = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "#             data_max = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "#             data_min = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "#             data_median = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "# #             data_var = data_all['phone_num'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)].var()\n",
    "\n",
    "\n",
    "#             data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "#             data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "#             data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "#             data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "#             data_all['data_var_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_var\n",
    "# # data_all['data_mean'] = 0\n",
    "# # data_all['data_max'] = 0\n",
    "# # data_all['data_min']= 0\n",
    "# data_all['data_median'] = 0\n",
    "\n",
    "# # data_all['data_mean_hour'] = 0\n",
    "# # data_all['data_max_hour'] = 0\n",
    "# # data_all['data_min_hour']= 0\n",
    "# data_all['data_median_hour'] = 0\n",
    "\n",
    "# # data_all['data_mean_week'] = 0\n",
    "# # data_all['data_max_week'] = 0\n",
    "# # data_all['data_min_week']= 0\n",
    "# data_all['data_median_week'] = 0\n",
    "\n",
    "# # data_all['data_mean_week_hour'] = 0\n",
    "# # data_all['data_max_week_hour'] = 0\n",
    "# # data_all['data_min_week_hour']= 0\n",
    "# # data_all['data_median_week_hour'] = 0\n",
    "# for i in range(1,34):\n",
    "\n",
    "# #     data_mean = data_all['phone_num'].mean()\n",
    "# #     data_max = data_all['phone_num'].max()\n",
    "# #     data_min = data_all['phone_num'].min()\n",
    "#     data_median = data_all['phone_num'].median()\n",
    "    \n",
    "# #     data_all['data_mean'][data_all['loc_id'] == i] = data_mean\n",
    "# #     data_all['data_max'][data_all['loc_id'] == i] = data_max\n",
    "# #     data_all['data_min'][data_all['loc_id'] == i] = data_min\n",
    "#     data_all['data_median'][data_all['loc_id'] == i] = data_median\n",
    "    \n",
    "#     for j in range(24):\n",
    "# #         data_mean = data_all['phone_num'][data_all['hour'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['hour'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['hour'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['hour'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_mean\n",
    "# #         data_all['data_max_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_max\n",
    "# #         data_all['data_min_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_min\n",
    "#         data_all['data_median_hour'][(data_all['loc_id'] == i)&(data_all['hour'] == j)] = data_median\n",
    "        \n",
    "#     for j in range(7):\n",
    "# #         data_mean = data_all['phone_num'][data_all['week'] == j].mean()\n",
    "# #         data_max = data_all['phone_num'][data_all['week'] == j].max()\n",
    "# #         data_min = data_all['phone_num'][data_all['week'] == j].min()\n",
    "#         data_median = data_all['phone_num'][data_all['week'] == j].median()\n",
    "\n",
    "# #         data_all['data_mean_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_mean\n",
    "# #         data_all['data_max_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_max\n",
    "# #         data_all['data_min_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_min\n",
    "#         data_all['data_median_week'][(data_all['loc_id'] == i)&(data_all['week'] == j)] = data_median\n",
    "#     for h in range(24):   \n",
    "#         for j in range(7):\n",
    "# #             data_mean = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].mean()\n",
    "# #             data_max = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].max()\n",
    "# #             data_min = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].min()\n",
    "#             data_median = data_all['phone_num'][(data_all['week'] == j)&(data_all['hour'] == h)].median()\n",
    "\n",
    "# #             data_all['data_mean_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_mean\n",
    "# #             data_all['data_max_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_max\n",
    "# #             data_all['data_min_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_min\n",
    "#             data_all['data_median_week_hour'][(data_all['loc_id'] == i)&(data_all['week'] == j)&(data_all['hour'] == h)] = data_median\n",
    "    \n",
    "data_all.to_csv('data/data_all.csv',index = False)         \n",
    "            \n",
    "#处理meo            \n",
    "data_meo = pd.read_csv('data/beijing_17_18_meo.csv')\n",
    "\n",
    "data_meo['wind_speed'][data_meo['wind_direction'] == 999017] = 0.1\n",
    "data_meo['wind_u'] = data_meo['wind_speed']*np.cos(data_meo['wind_direction'])\n",
    "data_meo['wind_v'] = data_meo['wind_speed']*np.sin(data_meo['wind_direction'])\n",
    "\n",
    "data_meo['weather'].replace(['Fog','Haze','Rain','Sunny/clear'],[1,2,3,4],inplace=True)\n",
    "\n",
    "data_meo['SSD'] = (1.818*data_meo['temperature']+18.18)*(0.88+0.002*data_meo['humidity'])+(data_meo['temperature']-32)/(45-data_meo['temperature'])-3.2*data_meo['wind_speed']+18.2\n",
    "del data_meo['wind_direction']         \n",
    "data_meo.to_csv('data/data_meo.csv',index = False)      \n",
    "\n",
    "#处理aq\n",
    "data_aq = pd.read_csv('data/aq_beifen.csv')\n",
    "data_aq['rate'].replace(['重度污染','严重污染','中度污染','轻度污染','良','优'],[1,2,3,4,5,6],inplace=True)\n",
    "data_aq.to_csv('data/data_aq.csv',index = False)  \n",
    "\n",
    "#合并数据\n",
    "data_aq = pd.read_csv('data/data_aq.csv')\n",
    "data_meo = pd.read_csv('data/data_meo.csv')\n",
    "data_base = pd.read_csv('data/data_all.csv')\n",
    "# print(data_base.isnull().sum())\n",
    "# print(data_base.columns.size)\n",
    "# print(data_base.iloc[:,0].size)\n",
    "# print(data_meo.columns.size)\n",
    "# print(data_meo.iloc[:,0].size)\n",
    "data = pd.merge(data_base, data_meo, how='inner', on=['time_stamp'])\n",
    "data = pd.merge(data, data_aq, how='inner', on=['date'])\n",
    "# print(data.columns.size)\n",
    "# print(data.iloc[:,0].size)\n",
    "\n",
    "\n",
    "\n",
    "data['loc_hour'] = data['loc_id']*100+data['hour']\n",
    "data['loc_week'] = data['loc_id']*100+data['week']\n",
    "data['loc_rate'] = data['loc_id']*100+data['rate']\n",
    "data['loc_weather'] = data['loc_id']*100+data['weather']\n",
    "\n",
    "# data_all['week_num_percent'] = data_all['week_num']/20\n",
    "# data['loc_week_num'] = data['loc_id']*100+data['week_num']\n",
    "\n",
    "data['hour_rate'] = data['hour']*100+data['rate']\n",
    "data['hour_weather'] = data['hour']*100+data['weather']\n",
    "data['hour_week'] = data['hour']*100+data['rate']\n",
    "\n",
    "data['week_rate'] = data['week']*100+data['rate']\n",
    "data['week_weather'] = data['week']*100+data['weather']\n",
    "\n",
    "data['rate_weather'] = data['rate']*100+data['weather']\n",
    "del data['date']\n",
    "data.to_csv('chouchoukan.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# datas = []\n",
    "# for i in range(1,34):\n",
    "#     path_to_bj_aq = \"./data/station_\"+str(i)+\"/\"\n",
    "\n",
    "#     bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "    \n",
    "#     for csv in bj_csv_list :\n",
    "#         if csv != '.DS_Store' and not csv.startswith(\"._\") :\n",
    "            \n",
    "#             path_to_file = path_to_bj_aq + csv\n",
    "#             data = pd.read_csv(path_to_file)  \n",
    "#             if data.empty == False:\n",
    "#                 datas.append(data)\n",
    "\n",
    "# data_all = pd.concat(datas, ignore_index=True)\n",
    "# data_all['loc_hour'] = data_all['loc_id']*100+data_all['hour']\n",
    "# data_all.to_csv('data/data_all.csv',index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##数据预处理buchong\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# sns.set_style('whitegrid')\n",
    "# %matplotlib inline\n",
    "\n",
    "# data_aq1_3 = pd.read_csv('data/station_8/month_03.csv')\n",
    "# data_aq1_4 = pd.read_csv('data/station_8/month_04.csv')\n",
    "# data_aq1_5 = pd.read_csv('data/station_8/month_05.csv')\n",
    "# data_aq1_6 = pd.read_csv('data/station_8/month_06.csv')\n",
    "# data_aq1_9 = pd.read_csv('data/station_8/month_09.csv')\n",
    "# data_aq1_10 = pd.read_csv('data/station_8/month_10.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_aq1_3.plot('time_stamp','phone_id')\n",
    "# data_aq1_4.plot('time_stamp','phone_id')\n",
    "# data_aq1_5.plot('time_stamp','phone_id')\n",
    "# data_aq1_6.plot('time_stamp','phone_id')\n",
    "# data_aq1_9.plot('time_stamp','phone_id')\n",
    "# data_aq1_10.plot('time_stamp','phone_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_bj_aq = \"./data/station_12/\"\n",
    "\n",
    "# bj_csv_list  = os.listdir(path_to_bj_aq)\n",
    "# datas = []\n",
    "# for csv in bj_csv_list :\n",
    "#     if csv != '.DS_Store' and not csv.startswith(\"._\"):\n",
    "#         path_to_file = path_to_bj_aq + csv\n",
    "#         data = pd.read_csv(path_to_file)\n",
    "#         if data.empty == False:\n",
    "#             datas.append(data)\n",
    "            \n",
    "# data_all = pd.concat(datas, ignore_index=True)\n",
    "# # data_all.set_index('time_stamp', inplace=True,drop = False)\n",
    "# # data_all.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_all.plot('time_stamp','phone_num',figsize=(15,15))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
