{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/zhangqq/.local/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/.local/lib/python3.6/site-packages/lightgbm/basic.py:681: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalid_0's rmse: 377.161\tvalid_0's mse: 377.161\n",
      "[200]\tvalid_0's rmse: 226.379\tvalid_0's mse: 226.379\n",
      "[300]\tvalid_0's rmse: 193.954\tvalid_0's mse: 193.954\n",
      "[400]\tvalid_0's rmse: 188.485\tvalid_0's mse: 188.485\n",
      "[500]\tvalid_0's rmse: 186.336\tvalid_0's mse: 186.336\n",
      "[600]\tvalid_0's rmse: 185.302\tvalid_0's mse: 185.302\n",
      "[700]\tvalid_0's rmse: 184.468\tvalid_0's mse: 184.468\n",
      "[800]\tvalid_0's rmse: 183.849\tvalid_0's mse: 183.849\n",
      "[900]\tvalid_0's rmse: 183.548\tvalid_0's mse: 183.548\n",
      "[1000]\tvalid_0's rmse: 183.398\tvalid_0's mse: 183.398\n",
      "Early stopping, best iteration is:\n",
      "[996]\tvalid_0's rmse: 183.376\tvalid_0's mse: 183.376\n",
      "loc_week                 5861\n",
      "data_max_week_hour       5450\n",
      "data_mean_week_hour      4598\n",
      "hour_rate                3876\n",
      "loc_rate                 3335\n",
      "loc_hour                 2741\n",
      "data_median_week_hour    2210\n",
      "data_min_week_hour       2160\n",
      "loc_weather              2142\n",
      "hour_weather             2093\n",
      "week_rate                2086\n",
      "O3_8h                    2010\n",
      "pressure                 1797\n",
      "week_weather             1650\n",
      "hour_week                1581\n",
      "humidity                 1532\n",
      "week_num                 1512\n",
      "loc_id                   1350\n",
      "SSD                      1263\n",
      "temperature              1187\n",
      "PM2.5                    1183\n",
      "hour                     1012\n",
      "SO2                       943\n",
      "NO2                       914\n",
      "wind_u                    806\n",
      "wind_v                    785\n",
      "wind_speed                688\n",
      "PM10                      610\n",
      "AQI                       583\n",
      "CO                        388\n",
      "week                      291\n",
      "rate_weather               64\n",
      "rate                       50\n",
      "weather                    13\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:67: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from dateutil.parser import parse\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "train = pd.read_csv('./chouchoukan.csv')\n",
    "dev = pd.read_csv('./chouchoukan_dev.csv')\n",
    "test = pd.read_csv('./test_X.csv')\n",
    "# train = train.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# test = test.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# print(train['holiday'])\n",
    "del test['holiday']\n",
    "del dev['holiday']\n",
    "del train['holiday']\n",
    "# train = train.astype('float64')\n",
    "predictors = [f for f in train.columns if f not in ['phone_num','time_stamp']]\n",
    "\n",
    "def evalerror(pred, df):\n",
    "    label = df.get_label().values.copy()\n",
    "    score = math.sqrt(mean_squared_error(label,pred))\n",
    "    return ('mse',score,False)\n",
    "\n",
    "print('Training..')\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split  \n",
    "# train_feat, val_feat, train_y, val_y = train_test_split(train[predictors],train['phone_num'],test_size = 0.2,random_state=42) \n",
    "train_feat = train[predictors]\n",
    "train_y = train['phone_num']\n",
    "\n",
    "val_feat = dev[predictors]\n",
    "val_y = dev['phone_num']\n",
    "lgb_train = lgb.Dataset(train_feat, train_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "lgb_val = lgb.Dataset(val_feat, val_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=50000,\n",
    "                valid_sets=lgb_val,\n",
    "                verbose_eval=100,\n",
    "                feval=evalerror,\n",
    "                early_stopping_rounds=100)\n",
    "print(pd.Series(gbm.feature_importance(),index = predictors).sort_values(ascending = False))\n",
    "# import pickle\n",
    "# with open('gbm_pm25_ld.pkl', 'wb') as f:\n",
    "#     pickle.dump(gbm, f)\n",
    "test_x = test[['loc_id','time_stamp']]\n",
    "\n",
    "\n",
    "test_x['time_stamp'] = test_x['time_stamp'].apply(lambda x: x.split(':')[0])  \n",
    "\n",
    "\n",
    "test_y = gbm.predict(test[predictors])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/.local/lib/python3.6/site-packages/lightgbm/basic.py:1036: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttraining's rmse: 336.533\ttraining's mse: 336.533\n",
      "[200]\ttraining's rmse: 184.953\ttraining's mse: 184.953\n",
      "[300]\ttraining's rmse: 142.894\ttraining's mse: 142.894\n",
      "[400]\ttraining's rmse: 126.167\ttraining's mse: 126.167\n",
      "[500]\ttraining's rmse: 117.293\ttraining's mse: 117.293\n",
      "[600]\ttraining's rmse: 111.598\ttraining's mse: 111.598\n",
      "[700]\ttraining's rmse: 107.28\ttraining's mse: 107.28\n",
      "[800]\ttraining's rmse: 103.76\ttraining's mse: 103.76\n",
      "[900]\ttraining's rmse: 100.605\ttraining's mse: 100.605\n",
      "data_max_week_hour       6875\n",
      "data_mean_week_hour      5319\n",
      "loc_week                 5035\n",
      "loc_hour                 3274\n",
      "hour_rate                3228\n",
      "loc_rate                 3174\n",
      "week_rate                3141\n",
      "data_min_week_hour       2358\n",
      "hour_weather             2343\n",
      "loc_weather              2245\n",
      "data_median_week_hour    2051\n",
      "week_weather             2023\n",
      "pressure                 1709\n",
      "O3_8h                    1571\n",
      "hour_week                1384\n",
      "PM10                     1378\n",
      "week_num                 1374\n",
      "SSD                      1209\n",
      "PM2.5                    1002\n",
      "temperature               987\n",
      "NO2                       941\n",
      "humidity                  868\n",
      "SO2                       734\n",
      "AQI                       700\n",
      "CO                        668\n",
      "wind_v                    654\n",
      "loc_id                    607\n",
      "wind_u                    551\n",
      "hour                      549\n",
      "wind_speed                431\n",
      "week                      155\n",
      "rate_weather              139\n",
      "rate                       69\n",
      "weather                    18\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:69: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from dateutil.parser import parse\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "train = pd.read_csv('./chouchoukan.csv')\n",
    "dev = pd.read_csv('./chouchoukan_dev.csv')\n",
    "train = pd.concat([train, dev],axis = 0)\n",
    "\n",
    "test = pd.read_csv('./test_X.csv')\n",
    "# train = train.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# test = test.drop(['data_min_week','data_median','data_min','data_max','data_mean'],axis = 1)\n",
    "# print(train['holiday'])\n",
    "del test['holiday']\n",
    "\n",
    "del train['holiday']\n",
    "# train = train.astype('float64')\n",
    "predictors = [f for f in train.columns if f not in ['phone_num','time_stamp']]\n",
    "\n",
    "def evalerror(pred, df):\n",
    "    label = df.get_label().values.copy()\n",
    "    score = math.sqrt(mean_squared_error(label,pred))\n",
    "    return ('mse',score,False)\n",
    "\n",
    "print('Training..')\n",
    "params = {\n",
    "    'learning_rate': 0.01,\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'sub_feature': 0.7,\n",
    "    'num_leaves': 60,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'feature_fraction': 0.7,\n",
    "    'min_data': 100,\n",
    "    'min_hessian': 1,\n",
    "    'verbose': -1,\n",
    "}\n",
    "\n",
    "# from sklearn.cross_validation import train_test_split  \n",
    "# train_feat, val_feat, train_y, val_y = train_test_split(train[predictors],train['phone_num'],test_size = 0.2,random_state=42) \n",
    "train_feat = train[predictors]\n",
    "train_y = train['phone_num']\n",
    "\n",
    "# val_feat = dev[predictors]\n",
    "# val_y = dev['phone_num']\n",
    "lgb_train = lgb.Dataset(train_feat, train_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "# lgb_val = lgb.Dataset(val_feat, val_y,categorical_feature=['loc_hour','loc_week','loc_rate','loc_weather','hour_rate','hour_weather','hour_week','week_rate','week_weather','rate_weather','loc_id','week','hour','weather','rate'])\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=996,\n",
    "                valid_sets=lgb_train,\n",
    "                verbose_eval=100,\n",
    "                feval=evalerror,\n",
    "                )\n",
    "print(pd.Series(gbm.feature_importance(),index = predictors).sort_values(ascending = False))\n",
    "# import pickle\n",
    "# with open('gbm_pm25_ld.pkl', 'wb') as f:\n",
    "#     pickle.dump(gbm, f)\n",
    "test_x = test[['loc_id','time_stamp']]\n",
    "\n",
    "\n",
    "test_x['time_stamp'] = test_x['time_stamp'].apply(lambda x: x.split(':')[0])  \n",
    "\n",
    "\n",
    "test_y = gbm.predict(test[predictors])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhangqq/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_y = pd.DataFrame(test_y)\n",
    "test_y.columns = ['num_of_people']\n",
    "test_y['num_of_people'] = test_y['num_of_people'].astype('int32')\n",
    "data = pd.concat([test_x, test_y],axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "data['num_of_people'][data['num_of_people']<=0] = 20\n",
    "data.to_csv('submit.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163.8577013640076\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('./submit.csv')\n",
    "dev = pd.read_csv('./submit248.csv')\n",
    "\n",
    "score = math.sqrt(mean_squared_error(train['num_of_people'],dev['num_of_people']))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
